{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Implementation of Basic Gradient Descent"
      ],
      "metadata": {
        "id": "45WwvR-WFS-x"
      },
      "id": "45WwvR-WFS-x"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "wjpPg9tFFQGB"
      },
      "id": "wjpPg9tFFQGB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7kgYA6XEXXS"
      },
      "outputs": [],
      "source": [
        "def ssr_gradient(x, y, b):\n",
        "    res = b[0] + b[1] * x - y\n",
        "    return res.mean(), (res * x).mean()  # .mean() is a method of np.ndarray\n",
        "\n",
        "def gradient_descent(\n",
        "    gradient, x, y, start, learn_rate=0.1, n_iter=50, tolerance=1e-06,\n",
        "    dtype=\"float64\"\n",
        "):\n",
        "    # Checking if the gradient is callable\n",
        "    if not callable(gradient):\n",
        "        raise TypeError(\"'gradient' must be callable\")\n",
        "\n",
        "    # Setting up the data type for NumPy arrays\n",
        "    dtype_ = np.dtype(dtype)\n",
        "\n",
        "    # Converting x and y to NumPy arrays\n",
        "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
        "    if x.shape[0] != y.shape[0]:\n",
        "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
        "\n",
        "    # Initializing the values of the variables\n",
        "    vector = np.array(start, dtype=dtype_)\n",
        "\n",
        "    # Setting up and checking the learning rate\n",
        "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
        "    if np.any(learn_rate <= 0):\n",
        "        raise ValueError(\"'learn_rate' must be greater than zero\")\n",
        "\n",
        "    # Setting up and checking the maximal number of iterations\n",
        "    n_iter = int(n_iter)\n",
        "    if n_iter <= 0:\n",
        "        raise ValueError(\"'n_iter' must be greater than zero\")\n",
        "\n",
        "    # Setting up and checking the tolerance\n",
        "    tolerance = np.array(tolerance, dtype=dtype_)\n",
        "    if np.any(tolerance <= 0):\n",
        "        raise ValueError(\"'tolerance' must be greater than zero\")\n",
        "\n",
        "    # Performing the gradient descent loop\n",
        "    for _ in range(n_iter):\n",
        "        # Recalculating the difference\n",
        "        diff = -learn_rate * np.array(gradient(x, y, vector), dtype_)\n",
        "\n",
        "        # Checking if the absolute difference is small enough\n",
        "        if np.all(np.abs(diff) <= tolerance):\n",
        "            break\n",
        "\n",
        "        # Updating the values of the variables\n",
        "        vector += diff\n",
        "\n",
        "    return vector if vector.shape else vector.item()\n",
        "\n"
      ],
      "id": "x7kgYA6XEXXS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic Gradient Descent Algorithms"
      ],
      "metadata": {
        "id": "PpNloXeLFoie"
      },
      "id": "PpNloXeLFoie"
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(\n",
        "    gradient, x, y, n_vars=None, start=None, learn_rate=0.1,\n",
        "    decay_rate=0.0, batch_size=1, n_iter=50, tolerance=1e-06,\n",
        "    dtype=\"float64\", random_state=None\n",
        "):\n",
        "    # Checking if the gradient is callable\n",
        "    if not callable(gradient):\n",
        "        raise TypeError(\"'gradient' must be callable\")\n",
        "\n",
        "    # Setting up the data type for NumPy arrays\n",
        "    dtype_ = np.dtype(dtype)\n",
        "\n",
        "    # Converting x and y to NumPy arrays\n",
        "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
        "    n_obs = x.shape[0]\n",
        "    if n_obs != y.shape[0]:\n",
        "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
        "    xy = np.c_[x.reshape(n_obs, -1), y.reshape(n_obs, 1)]\n",
        "\n",
        "    # Initializing the random number generator\n",
        "    seed = None if random_state is None else int(random_state)\n",
        "    rng = np.random.default_rng(seed=seed)\n",
        "\n",
        "    # Initializing the values of the variables\n",
        "    vector = (\n",
        "        rng.normal(size=int(n_vars)).astype(dtype_)\n",
        "        if start is None else\n",
        "        np.array(start, dtype=dtype_)\n",
        "    )\n",
        "\n",
        "    # Setting up and checking the learning rate\n",
        "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
        "    if np.any(learn_rate <= 0):\n",
        "        raise ValueError(\"'learn_rate' must be greater than zero\")\n",
        "\n",
        "    # Setting up and checking the decay rate\n",
        "    decay_rate = np.array(decay_rate, dtype=dtype_)\n",
        "    if np.any(decay_rate < 0) or np.any(decay_rate > 1):\n",
        "        raise ValueError(\"'decay_rate' must be between zero and one\")\n",
        "\n",
        "    # Setting up and checking the size of minibatches\n",
        "    batch_size = int(batch_size)\n",
        "    if not 0 < batch_size <= n_obs:\n",
        "        raise ValueError(\n",
        "            \"'batch_size' must be greater than zero and less than \"\n",
        "            \"or equal to the number of observations\"\n",
        "        )\n",
        "\n",
        "    # Setting up and checking the maximal number of iterations\n",
        "    n_iter = int(n_iter)\n",
        "    if n_iter <= 0:\n",
        "        raise ValueError(\"'n_iter' must be greater than zero\")\n",
        "\n",
        "    # Setting up and checking the tolerance\n",
        "    tolerance = np.array(tolerance, dtype=dtype_)\n",
        "    if np.any(tolerance <= 0):\n",
        "        raise ValueError(\"'tolerance' must be greater than zero\")\n",
        "\n",
        "    # Setting the difference to zero for the first iteration\n",
        "    diff = 0\n",
        "\n",
        "    # Performing the gradient descent loop\n",
        "    for _ in range(n_iter):\n",
        "        # Shuffle x and y\n",
        "        rng.shuffle(xy)\n",
        "\n",
        "        # Performing minibatch moves\n",
        "        for start in range(0, n_obs, batch_size):\n",
        "            stop = start + batch_size\n",
        "            x_batch, y_batch = xy[start:stop, :-1], xy[start:stop, -1:]\n",
        "\n",
        "            # Recalculating the difference\n",
        "            grad = np.array(gradient(x_batch, y_batch, vector), dtype_)\n",
        "            diff = decay_rate * diff - learn_rate * grad\n",
        "\n",
        "            # Checking if the absolute difference is small enough\n",
        "            if np.all(np.abs(diff) <= tolerance):\n",
        "                break\n",
        "\n",
        "            # Updating the values of the variables\n",
        "            vector += diff\n",
        "\n",
        "    return vector if vector.shape else vector.item()"
      ],
      "metadata": {
        "id": "4SQC9l78Fs_O"
      },
      "id": "4SQC9l78Fs_O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTQOaPYbEXXc",
        "outputId": "87bee281-0ee0-4875-8a9d-9fe129626742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigma = 0.1\n",
            "theta0 =  0.3141592653589793 theta1 =  9.869604401089358\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.33037592, 9.83151664])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Main\n",
        "M = 512;  theta0 = np.pi/10; theta1 = np.pi*np.pi; \n",
        "X = np.random.rand(M,1)\n",
        "sigma = .1\n",
        "print('sigma =', sigma)\n",
        "y = theta0 + theta1 * X + sigma*np.random.randn(M,1) \n",
        "print('theta0 = ', theta0, 'theta1 = ', theta1)\n",
        "gradient_descent(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.0008,n_iter=100_000)"
      ],
      "id": "OTQOaPYbEXXc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOceg9kXEXXd"
      },
      "outputs": [],
      "source": [
        "# sgd(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.0008, batch_size=3, n_iter=100_000, random_state=0)"
      ],
      "id": "zOceg9kXEXXd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SPwtFYbEXXe",
        "outputId": "18ea7574-9b67-4dfc-9b8d-9d97b0ca0238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigma = 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.42107039, 9.6995121 ])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "sigma = 1\n",
        "print('sigma =', sigma)\n",
        "y = theta0 + theta1 * X + sigma*np.random.randn(M,1) \n",
        "gradient_descent(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.0008,n_iter=100_000)"
      ],
      "id": "_SPwtFYbEXXe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O241Fw2JEXXe",
        "outputId": "6ec30b33-039c-48b2-febb-d03bc963a24b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigma = 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.48160057, 10.18172926])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "sigma = 10\n",
        "print('sigma =', sigma)\n",
        "y = theta0 + theta1 * X + sigma*np.random.randn(M,1) \n",
        "gradient_descent(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.0008,n_iter=100_000)"
      ],
      "id": "O241Fw2JEXXe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAyGn9OUEXXf",
        "outputId": "aa3702fb-2cd8-4070-88b2-6f4f6a6b29c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigma = 10 learn rate = 0.9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.50088756, 10.2188327 ])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "print('sigma =', sigma, 'learn rate =', 0.9)\n",
        "gradient_descent(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.9,n_iter=100_000)"
      ],
      "id": "zAyGn9OUEXXf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6xqjopsEXXf",
        "outputId": "1ad8c648-8002-48d1-9e18-a3b3ac1a8d8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.83296786,  4.63803725])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "sgd(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.9, batch_size=3, n_iter=1_000, random_state=0)"
      ],
      "id": "h6xqjopsEXXf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4tel2EKEXXg",
        "outputId": "b4b5590c-2474-4b9c-c3c9-ea35b5ee60c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigma = 10 learn rate = 0.9 N. iterations 100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.49275831, 10.20319402])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "print('sigma =', sigma, 'learn rate =', 0.9, 'N. iterations', 100)\n",
        "gradient_descent(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.9,n_iter=100)"
      ],
      "id": "h4tel2EKEXXg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I95PQlH1EXXh",
        "outputId": "3c1387ae-71ad-4194-8233-da2190233cdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.50050253,  5.36386797])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "sgd(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.9, batch_size=3, n_iter=100, random_state=0)"
      ],
      "id": "I95PQlH1EXXh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrgDs5xZEXXh",
        "outputId": "e76c78c7-d88d-4978-aced-93a74e054de4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigma = 10 , learn rate = 0.9 , N. iterations 100 , M= 16\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.31349259, -0.1776592 ])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "M = 16\n",
        "X = np.random.rand(M,1)\n",
        "y = theta0 + theta1 * X + sigma*np.random.randn(M,1)\n",
        "print('sigma =', sigma, ', learn rate =', 0.9, ', N. iterations', 100, ', M=',M)\n",
        "gradient_descent(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.9,n_iter=100)"
      ],
      "id": "XrgDs5xZEXXh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiWPN_BuEXXi",
        "outputId": "398c8870-5a26-493c-fc91-110233cb18af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.96727037, 2.78609077])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "sgd(ssr_gradient, X, y, start=[0.5, 0.5], learn_rate=0.9, batch_size=3, n_iter=100, random_state=0)"
      ],
      "id": "hiWPN_BuEXXi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   https://realpython.com/gradient-descent-algorithm-python/\n",
        "2.   https://medium.com/code-heroku/gradient-descent-for-machine-learning-3d871fa48b4c\n",
        "3.   https://medium.com/@pcmaldonado/linear-regression-normal-equation-gradient-descent-from-scratch-dc8c0f51940\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VXk-JsON6TIp"
      },
      "id": "VXk-JsON6TIp"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "04cGradDesc.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}